# -*- coding: utf-8 -*-
"""Copy of Project Disc 300.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14KQmN1QQXucf3Ov0aoe6Ik_KAElrxOD1
"""



#  Imports and Parameters

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, Cropping2D, Dropout, Flatten, Dense, LeakyReLU
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Set image and training parameters
IMG_HEIGHT = 256
IMG_WIDTH = 256
BATCH_SIZE = 4
EPOCHS = 100             # For demonstration; increase for a better-trained model.
STEPS_PER_EPOCH = 50     # Adjust based on dataset size

from google.colab import drive
drive.mount('/content/drive')


#  Paths for your dataset

DAMAGED_DIR = '/content/drive/MyDrive/Project /Dataset/damaged/'       # Folder containing damaged images
UNDAMAGED_DIR ='/content/drive/MyDrive/Project /Dataset/undamaged/'  # Folder containing undamaged (ground-truth) images

# 3. Data Preprocessing and Generators

# Function to normalize images from [0,255] to [-1,1]
def preprocess_tanh(img):
    return (img / 127.5) - 1

# Create an ImageDataGenerator that uses our custom preprocessing
datagen = ImageDataGenerator(preprocessing_function=preprocess_tanh, horizontal_flip=True)

# Damaged and Undamaged Generator

damaged_generator = datagen.flow_from_directory(
    directory=os.path.dirname(os.path.normpath(DAMAGED_DIR)),
    classes=[os.path.basename(os.path.normpath(DAMAGED_DIR))],
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode=None,
    shuffle=True,
    seed=42
)

undamaged_generator = datagen.flow_from_directory(
    directory=os.path.dirname(os.path.normpath(UNDAMAGED_DIR)),
    classes=[os.path.basename(os.path.normpath(UNDAMAGED_DIR))],
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE,
    class_mode=None,
    shuffle=True,
    seed=42
)

# Paired generator: yields a tuple of (damaged_images, undamaged_images)
def paired_generator(gen1, gen2):
    while True:
        damaged_imgs = next(gen1)
        undamaged_imgs = next(gen2)
        yield (damaged_imgs, undamaged_imgs)

train_generator = paired_generator(damaged_generator, undamaged_generator)

#  Model Definitions


#  Generator: Encoderâ€“Decoder with a Cropping layer
def build_generator(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):
    inp = Input(shape=input_shape)

    # Encoder
    x = Conv2D(64, kernel_size=4, strides=2, activation='relu', padding='same')(inp)
    x = Conv2D(128, kernel_size=4, strides=2, activation='relu', padding='same')(x)
    x = Conv2D(256, kernel_size=4, strides=2, activation='relu', padding='same')(x)

    # Bottleneck
    x = Conv2D(512, kernel_size=4, strides=2, activation='relu', padding='same')(x)

    # Decoder
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(256, kernel_size=4, activation='relu', padding='same')(x)
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(128, kernel_size=4, activation='relu', padding='same')(x)
    x = UpSampling2D(size=(2, 2))(x)
    x = Conv2D(64, kernel_size=4, activation='relu', padding='same')(x)
    x = UpSampling2D(size=(2, 2))(x)
    #  tanh activation so that output is in [-1,1]
    x = Conv2D(3, kernel_size=3, activation='tanh', padding='same')(x)

    # Crop 4 pixels from the width if needed (adjust cropping as desired)
    out = x
    model = Model(inputs=inp, outputs=out, name='Generator')
    return model

#  Discriminator: A simple CNN
def build_discriminator(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):
    inp = Input(shape=input_shape)
    x = Conv2D(64, kernel_size=4, strides=2, padding='same')(inp)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(128, kernel_size=4, strides=2, padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(256, kernel_size=4, strides=2, padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(512, kernel_size=4, strides=2, padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Flatten()(x)
    out = Dense(1, activation='sigmoid')(x)
    model = Model(inputs=inp, outputs=out, name='Discriminator')
    return model

#  Combined GAN: Connects generator and discriminator
def build_gan(generator, discriminator, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)):
    # Freeze discriminator weights when training GAN
    discriminator.trainable = False
    # discriminator.trainable = True
    # Freeze generator weights when training Discriminator
    # generator.trainable = False
    inp = Input(shape=input_shape)
    restored_img = generator(inp)
    validity = discriminator(restored_img)
    model = Model(inputs=inp, outputs=[restored_img, validity], name='GAN')
    return model

# Instantiate models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

generator.load_weights('/content/drive/MyDrive/Project /generator200.h5')
discriminator.load_weights('/content/drive/MyDrive/Project /discriminator200.h5')

#  Compile Models

# Loss functions
loss_reconstruction = tf.keras.losses.MeanSquaredError()  # For image reconstruction (L2 loss)
loss_adversarial = tf.keras.losses.BinaryCrossentropy()     # For real/fake discrimination

# Optimizers
opt_gen = Adam(learning_rate=0.0002, beta_1=0.5)
opt_disc = Adam(learning_rate=0.0002, beta_1=0.5)

# Compile discriminator: it learns to classify real vs. fake images.
discriminator.compile(loss=loss_adversarial, optimizer=opt_disc, metrics=['accuracy'])

# Weight for reconstruction loss (adjust as needed)
lambda_recon = 100

# Compile GAN: it outputs the restored image (for reconstruction loss) and discriminator decision.
gan.compile(loss=[loss_reconstruction, loss_adversarial],
            loss_weights=[lambda_recon, 1],
            optimizer=opt_gen)

#  Training Loop

real_label = np.ones((BATCH_SIZE, 1))
fake_label = np.zeros((BATCH_SIZE, 1))

print("Resuming training...")
initial_epoch = 200 # trained for 100 epochs previously.
total_epochs = 300 # desired total epochs.

for epoch in range(initial_epoch, total_epochs):
    print(f"Epoch {epoch+1}/{total_epochs}")
    for step in range(STEPS_PER_EPOCH):
        #  batch of data (damaged and undamaged images)
        damaged_imgs, undamaged_imgs = next(train_generator)

        # --- Train the Generator (via GAN model) ---
        # The GAN model updates the generator so that its output is both close to undamaged_imgs
        # (reconstruction loss) and fools the discriminator (adversarial loss).
        gan_loss = gan.train_on_batch(damaged_imgs, [undamaged_imgs, real_label])

        # --- Train the Discriminator ---
        # Generate fake (restored) images using the generator.
        restored_imgs = generator.predict(damaged_imgs)
        d_loss_real = discriminator.train_on_batch(undamaged_imgs, real_label)
        d_loss_fake = discriminator.train_on_batch(restored_imgs, fake_label)
        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

        if step % 10 == 0:
            print(f"  Step {step}/{STEPS_PER_EPOCH} | GAN Loss: {gan_loss[0]:.4f} | D Loss: {d_loss[0]:.4f}")


    # 7. Visualization After Each Epoch

    sample_damaged, sample_undamaged = next(train_generator)
    sample_restored = generator.predict(sample_damaged)

    # Convert outputs from [-1,1] to [0,1] for display
    sample_damaged_disp = (sample_damaged + 1) / 2.0
    sample_undamaged_disp = (sample_undamaged + 1) / 2.0
    sample_restored_disp = (sample_restored + 1) / 2.0

    n = min(3, sample_damaged.shape[0])
    plt.figure(figsize=(12, 4 * n))
    for i in range(n):
        # Damaged image
        plt.subplot(n, 3, i * 3 + 1)
        plt.imshow(sample_damaged_disp[i])
        plt.title("Damaged")
        plt.axis('off')
        # Restored image
        plt.subplot(n, 3, i * 3 + 2)
        plt.imshow(sample_restored_disp[i])
        plt.title("Restored")
        plt.axis('off')
        # Ground-truth undamaged image
        plt.subplot(n, 3, i * 3 + 3)
        plt.imshow(sample_undamaged_disp[i])
        plt.title("Undamaged")
        plt.axis('off')
    plt.suptitle(f"Epoch {epoch+1}")
    plt.tight_layout()
    plt.show()

print("Training complete!")

generator.save('/content/drive/MyDrive/Project /generator300.h5')
discriminator.save('/content/drive/MyDrive/Project /discriminator300.h5')

# -------------------------------
# Setup Virtual Display (for headless environments)
# -------------------------------
!apt-get update
!apt-get install -y xvfb

!pip install pyvirtualdisplay

from pyvirtualdisplay import Display
display = Display(visible=0, size=(1400, 900))
display.start()

# -------------------------------
# Imports
# -------------------------------
import tkinter as tk
from tkinter import filedialog, messagebox
from PIL import Image, ImageTk
import numpy as np
import matplotlib
matplotlib.use('TkAgg')  # Use TkAgg backend for matplotlib
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.figure import Figure
import tensorflow as tf

# -------------------------------
# Global Parameters
# -------------------------------
IMG_HEIGHT = 256
IMG_WIDTH = 256

# -------------------------------
# Dummy Generator Model (Replace this with your actual model!)
# -------------------------------
# For demonstration purposes, this dummy model simply returns its input.
# Replace it with your trained generator (for example, using tf.keras.models.load_model).
generator = tf.keras.Sequential([tf.keras.layers.Lambda(lambda x: x)])
print("Dummy generator loaded. Replace with your trained generator model.")

# -------------------------------
# Preprocessing and Postprocessing Functions
# -------------------------------
def preprocess_image(pil_img):
    """
    Resize and normalize a PIL image to [-1, 1] range.
    Assumes the input image is in RGB format.
    """
    # Resize to the model's input size.
    img_resized = pil_img.resize((IMG_WIDTH, IMG_HEIGHT))
    # Convert to a numpy array.
    img_array = np.array(img_resized)
    # If the image has an alpha channel, discard it.
    if img_array.ndim == 3 and img_array.shape[-1] == 4:
        img_array = img_array[..., :3]
    # Normalize from [0, 255] to [-1, 1].
    img_norm = (img_array / 127.5) - 1.0
    return img_norm

def postprocess_image(img_array):
    """
    Convert a network output from [-1, 1] to a PIL image.
    """
    # If a batch dimension exists, remove it.
    if img_array.ndim == 4:
        img_array = img_array[0]
    # Scale from [-1, 1] to [0, 1].
    img_rescaled = (img_array + 1) / 2.0
    # Convert to [0, 255] and to uint8.
    img_uint8 = (img_rescaled * 255).astype(np.uint8)
    return Image.fromarray(img_uint8)

# -------------------------------
# GUI Setup Using Tkinter
# -------------------------------
root = tk.Tk()
root.title("Artifact Restoration GUI")

# Create two frames: one for the input image and one for the restored output.
frame_input = tk.Frame(root, padx=10, pady=10)
frame_input.pack(side="left", fill="both", expand=True)
frame_output = tk.Frame(root, padx=10, pady=10)
frame_output.pack(side="right", fill="both", expand=True)

# Title labels for each frame.
label_input_title = tk.Label(frame_input, text="Input Image", font=("Arial", 14))
label_input_title.pack(pady=5)
label_output_title = tk.Label(frame_output, text="Restored Image", font=("Arial", 14))
label_output_title.pack(pady=5)

# Labels for displaying images.
label_input_img = tk.Label(frame_input)
label_input_img.pack()
label_output_img = tk.Label(frame_output)
label_output_img.pack()

# Global variable to hold the loaded image.
loaded_image = None

def load_image():
    """
    Opens a file dialog to let the user select an image,
    and displays the selected image in the input frame.
    """
    global loaded_image
    file_path = filedialog.askopenfilename(
        filetypes=[("Image Files", "*.jpg;*.jpeg;*.png;*.bmp"), ("All Files", "*.*")]
    )
    if file_path:
        try:
            loaded_image = Image.open(file_path).convert("RGB")
        except Exception as e:
            messagebox.showerror("Error", f"Failed to open image:\n{e}")
            return
        # For display purposes, resize the image.
        display_image = loaded_image.resize((IMG_WIDTH, IMG_HEIGHT))
        img_tk = ImageTk.PhotoImage(display_image)
        label_input_img.configure(image=img_tk)
        label_input_img.image = img_tk

def restore_image():
    """
    Uses the generator model to process the loaded image and displays the restored image.
    """
    global loaded_image
    if loaded_image is None:
        messagebox.showwarning("No Image Loaded", "Please load an image first!")
        return

    # Preprocess the input image.
    img_norm = preprocess_image(loaded_image)
    # Add a batch dimension.
    img_input = np.expand_dims(img_norm, axis=0)
    # Use the generator model to restore the image.
    restored_output = generator.predict(img_input)
    # Postprocess the restored output.
    restored_img = postprocess_image(restored_output)
    # Update the output display.
    update_output_image(restored_img)

def update_output_image(restored_img):
    """
    Updates the restored image display and embeds a matplotlib plot.
    """
    # Resize for display.
    display_restored = restored_img.resize((IMG_WIDTH, IMG_HEIGHT))
    img_tk_restored = ImageTk.PhotoImage(display_restored)
    label_output_img.configure(image=img_tk_restored)
    label_output_img.image = img_tk_restored

    # Create a matplotlib figure to display the image.
    fig = Figure(figsize=(5, 4), dpi=100)
    ax = fig.add_subplot(111)
    ax.imshow(restored_img)
    ax.set_title("Restored Image")
    ax.axis('off')

    # Remove any previous canvas if it exists.
    for widget in frame_output.winfo_children():
        if isinstance(widget, FigureCanvasTkAgg):
            widget.get_tk_widget().destroy()

    # Embed the figure in the Tkinter frame.
    canvas = FigureCanvasTkAgg(fig, master=frame_output)
    canvas.draw()
    canvas.get_tk_widget().pack()

# Create Buttons for "Load Image" and "RESTORE".
btn_load = tk.Button(root, text="Load Image", command=load_image, width=20, font=("Arial", 12))
btn_load.pack(pady=10)
btn_restore = tk.Button(root, text="RESTORE", command=restore_image, width=20, font=("Arial", 12))
btn_restore.pack(pady=10)

# -------------------------------
# Start the GUI (on the main thread)
# -------------------------------
print("Starting GUI on the main thread.")
root.mainloop()



from google.colab import drive
drive.mount('/content/drive')

import io
import numpy as np
from PIL import Image
import tensorflow as tf
import ipywidgets as widgets
from IPython.display import display, clear_output

# ---------------------------------
# Parameters and Dummy Generator
# ---------------------------------
IMG_HEIGHT = 256
IMG_WIDTH = 256

# Dummy generator: Replace this with your actual trained generator model.
# For example: generator = tf.keras.models.load_model('path_to_your_generator.h5')
generator = tf.keras.models.load_model('/content/drive/MyDrive/Project/generator300.h5')
print("Trained generator model loaded.")

# ---------------------------------
# Preprocessing and Postprocessing Functions
# ---------------------------------
def preprocess_image(pil_img):
    """
    Resize and normalize a PIL image to [-1, 1].
    """
    # Resize the image to the required dimensions.
    img_resized = pil_img.resize((IMG_WIDTH, IMG_HEIGHT))
    # Convert to a NumPy array.
    img_array = np.array(img_resized)
    # Discard the alpha channel if present.
    if img_array.ndim == 3 and img_array.shape[-1] == 4:
        img_array = img_array[..., :3]
    # Normalize from [0, 255] to [-1, 1].
    img_norm = (img_array / 127.5) - 1.0
    return img_norm

def postprocess_image(img_array):
    """
    Convert a network output from [-1, 1] to a PIL image.
    """
    # Remove batch dimension if necessary.
    if img_array.ndim == 4:
        img_array = img_array[0]
    # Scale from [-1, 1] to [0, 1].
    img_rescaled = (img_array + 1) / 2.0
    # Convert to [0, 255] and then to uint8.
    img_uint8 = (img_rescaled * 255).astype(np.uint8)
    return Image.fromarray(img_uint8)

# ---------------------------------
# Build the Interface Using ipywidgets
# ---------------------------------
# Create a file upload widget (accepting a single image file)
upload_widget = widgets.FileUpload(accept='image/*', multiple=False)

# Create a RESTORE button.
restore_button = widgets.Button(
    description="RESTORE",
    button_style='success',
    layout=widgets.Layout(width='150px')
)

# Create an output area for displaying images.
output_widget = widgets.Output()

def on_restore_clicked(b):
    with output_widget:
        clear_output()
        if upload_widget.value:
            # Get the first uploaded file.
            uploaded_file = list(upload_widget.value.values())[0]
            content = uploaded_file['content']
            # Convert bytes to a PIL image.
            input_image = Image.open(io.BytesIO(content)).convert("RGB")
            print("Input Image:")
            display(input_image)

            # Preprocess the image.
            img_norm = preprocess_image(input_image)
            img_input = np.expand_dims(img_norm, axis=0)

            # Run inference with the generator.
            restored_output = generator.predict(img_input)
            restored_image = postprocess_image(restored_output)

            print("Restored Image:")
            display(restored_image)
        else:
            print("Please upload an image first.")

restore_button.on_click(on_restore_clicked)

# Display the interface
ui = widgets.VBox([upload_widget, restore_button, output_widget])
display(ui)

import os
import numpy as np
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import tensorflow as tf # Import tensorflow

# Assuming you have your trained generator loaded as 'generator'
# Load your test dataset into 'damaged_images' and 'undamaged_images'
DAMAGED_DIR = '/content/drive/MyDrive/Project /Dataset/damaged/'
UNDAMAGED_DIR = '/content/drive/MyDrive/Project /Dataset/undamaged/'

# Load your trained generator model
generator = tf.keras.models.load_model('/content/drive/MyDrive/Project /generator300.h5') # Load the generator model
print("Trained generator model loaded.")

# Define preprocess_image and postprocess_image functions:
def preprocess_image(pil_img):
    """
    Resize and normalize a PIL image to [-1, 1].
    Assumes the input image is in RGB format.
    """
    # Resize to the model's input size.
    img_resized = pil_img.resize((256, 256))  # Replace with your image size
    # Convert to a numpy array.
    img_array = np.array(img_resized)
    # If the image has an alpha channel, discard it.
    if img_array.ndim == 3 and img_array.shape[-1] == 4:
        img_array = img_array[..., :3]
    # Normalize from [0, 255] to [-1, 1].
    img_norm = (img_array / 127.5) - 1.0
    return img_norm

def postprocess_image(img_array):
    """
    Convert a network output from [-1, 1] to a PIL image.
    """
    # If a batch dimension exists, remove it.
    if img_array.ndim == 4:
        img_array = img_array[0]
    # Scale from [-1, 1] to [0, 1].
    img_rescaled = (img_array + 1) / 2.0
    # Convert to [0, 255] and to uint8.
    img_uint8 = (img_rescaled * 255).astype(np.uint8)
    return Image.fromarray(img_uint8)


damaged_images = []
for filename in os.listdir(DAMAGED_DIR):
    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add other image extensions if needed
        img_path = os.path.join(DAMAGED_DIR, filename)
        img = Image.open(img_path).convert("RGB")  # Convert to RGB if necessary
        damaged_images.append(img)

undamaged_images = []
for filename in os.listdir(UNDAMAGED_DIR):
    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add other image extensions if needed
        img_path = os.path.join(UNDAMAGED_DIR, filename)
        img = Image.open(img_path).convert("RGB")  # Convert to RGB if necessary
        undamaged_images.append(img)

# Number of images to evaluate
num_images = len(damaged_images)

# Lists to store PSNR and SSIM values
psnr_values = []
ssim_values = []

for i in range(num_images):
    # Preprocess damaged image
    damaged_img = preprocess_image(damaged_images[i])
    damaged_img = np.expand_dims(damaged_img, axis=0)

    # Generate restored image
    restored_img = generator.predict(damaged_img)
    restored_img = postprocess_image(restored_img)

    # Preprocess undamaged image (ground truth)
    # undamaged_img = preprocess_image(undamaged_images[i]) # Use preprocess_image for consistency
    # undamaged_img = np.expand_dims(undamaged_img, axis=0) # Ensures undamaged_img has the same shape as restored_img
    undamaged_img = np.array(undamaged_images[i].resize((256, 256))) # Resize using PIL and then convert to NumPy array


    # Convert images to NumPy arrays for evaluation
    restored_img = np.array(restored_img)
    #undamaged_img = np.array(undamaged_images[i]) # Remove or comment out this line

    # Calculate PSNR
    psnr_value = psnr(undamaged_img, restored_img, data_range=255)
    psnr_values.append(psnr_value)

    # Calculate SSIM with win_size adjustment
    # ssim_value = ssim(undamaged_img, restored_img, data_range=255, multichannel=True,
    #                   win_size=min(7, undamaged_img.shape[0] - 1, undamaged_img.shape[1] - 1))
    #                   # win_size is adjusted to be odd and within image bounds
    # ssim_values.append(ssim_value)

# Calculate average PSNR and SSIM
avg_psnr = np.mean(psnr_values)
# avg_ssim = np.mean(ssim_values)


print(f"Average PSNR: {avg_psnr:.2f}")
# print(f"Average SSIM: {avg_ssim:.2f}")

import os
import numpy as np
from PIL import Image
from skimage.metrics import peak_signal_noise_ratio as psnr
from skimage.metrics import structural_similarity as ssim
import tensorflow as tf # Import tensorflow

# Assuming you have your trained generator loaded as 'generator'
# Load your test dataset into 'damaged_images' and 'undamaged_images'
DAMAGED_DIR = '/content/drive/MyDrive/Project /Dataset/damaged/'
UNDAMAGED_DIR = '/content/drive/MyDrive/Project /Dataset/undamaged/'

# Load your trained generator model
generator = tf.keras.models.load_model('/content/drive/MyDrive/Project /generator300.h5') # Load the generator model
print("Trained generator model loaded.")

# Define preprocess_image and postprocess_image functions:
def preprocess_image(pil_img):
    """
    Resize and normalize a PIL image to [-1, 1].
    Assumes the input image is in RGB format.
    """
    # Resize to the model's input size.
    img_resized = pil_img.resize((256, 256))  # Replace with your image size
    # Convert to a numpy array.
    img_array = np.array(img_resized)
    # If the image has an alpha channel, discard it.
    if img_array.ndim == 3 and img_array.shape[-1] == 4:
        img_array = img_array[..., :3]
    # Normalize from [0, 255] to [-1, 1].
    img_norm = (img_array / 127.5) - 1.0
    return img_norm

def postprocess_image(img_array):
    """
    Convert a network output from [-1, 1] to a PIL image.
    """
    # If a batch dimension exists, remove it.
    if img_array.ndim == 4:
        img_array = img_array[0]
    # Scale from [-1, 1] to [0, 1].
    img_rescaled = (img_array + 1) / 2.0
    # Convert to [0, 255] and to uint8.
    img_uint8 = (img_rescaled * 255).astype(np.uint8)
    return Image.fromarray(img_uint8)


damaged_images = []
for filename in os.listdir(DAMAGED_DIR):
    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add other image extensions if needed
        img_path = os.path.join(DAMAGED_DIR, filename)
        img = Image.open(img_path).convert("RGB")  # Convert to RGB if necessary
        damaged_images.append(img)

undamaged_images = []
for filename in os.listdir(UNDAMAGED_DIR):
    if filename.endswith(('.jpg', '.jpeg', '.png')):  # Add other image extensions if needed
        img_path = os.path.join(UNDAMAGED_DIR, filename)
        img = Image.open(img_path).convert("RGB")  # Convert to RGB if necessary
        undamaged_images.append(img)

# Number of images to evaluate
num_images = len(damaged_images)

# Lists to store PSNR and SSIM values
psnr_values = []
ssim_values = []

for i in range(num_images):
    # Preprocess damaged image
    damaged_img = preprocess_image(damaged_images[i])
    damaged_img = np.expand_dims(damaged_img, axis=0)

    # Generate restored image
    restored_img = generator.predict(damaged_img)
    restored_img = postprocess_image(restored_img)

    # Ensure both images have the same shape and data type
    undamaged_img = np.array(undamaged_images[i].resize((256, 256)))
    restored_img = np.array(restored_img)
    undamaged_img = undamaged_img.astype(np.uint8) # Or restored_img.dtype
    restored_img = restored_img.astype(np.uint8)  # Or undamaged_img.dtype

    # Explicitly set win_size based on the smaller dimension of the images
    win_size = min(3, restored_img.shape[0] - 1, restored_img.shape[1] - 1,
                      undamaged_img.shape[0] - 1, undamaged_img.shape[1] - 1)

    if win_size % 2 == 0:  # Make sure win_size is odd
        win_size -= 1
    if win_size <= 1:  # If win_size is too small, set to 3
        win_size = 3

    # Calculate SSIM with win_size adjustment and handling channel mismatch:
    try:
        ssim_value = ssim(undamaged_img, restored_img, data_range=255,
                          multichannel=True, win_size=win_size)
        ssim_values.append(ssim_value)
    except ValueError as e:
        print(f"Error calculating SSIM for image {i}: {e}")
        # Handle the error, for example, skip the image or set SSIM to a default value

# Calculate average SSIM
avg_ssim = np.mean(ssim_values)
print(f"Average SSIM: {avg_ssim:.2f}")